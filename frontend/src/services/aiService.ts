/**
 * AI Service - æ ¸å¿ƒ AI è°ƒç”¨æœåŠ¡
 * ä½¿ç”¨åç«¯ä»£ç†è¿›è¡Œ API è°ƒç”¨ï¼Œè§£å†³ CORS é—®é¢˜
 */

import { getActiveLlmApi, ApiConfig } from './settingsService';
import { buildSystemPrompt } from './promptService';



export interface ChatMessage {
    role: 'system' | 'user' | 'assistant';
    content: string;
    images?: string[]; // base64 images
}

export interface GenerationOptions {
    temperature?: number;
    top_p?: number;
}

// ... unchanged imports and interfaces ...

/**
 * æ„å»ºè¯·æ±‚ä½“ï¼ˆOpenAI æ ¼å¼ï¼‰
 */
function buildOpenAIRequestBody(
    messages: ChatMessage[],
    model: string,
    stream: boolean = true,
    options?: GenerationOptions
): object {
    const formattedMessages = messages.map(m => {
        if (m.role === 'user' && m.images && m.images.length > 0) {
            return {
                role: m.role,
                content: [
                    { type: 'text', text: m.content },
                    ...m.images.map(img => ({
                        type: 'image_url',
                        image_url: {
                            url: img.startsWith('data:') ? img : `data:image/jpeg;base64,${img}`
                        }
                    }))
                ]
            };
        }
        return {
            role: m.role,
            content: m.content
        };
    });

    return {
        model,
        messages: formattedMessages,
        stream,
        temperature: options?.temperature ?? 0.7,
        top_p: options?.top_p ?? 1.0,
        max_tokens: 4096,
    };
}

/**
 * æ„å»ºè¯·æ±‚ä½“ï¼ˆAnthropic æ ¼å¼ï¼‰
 */
function buildAnthropicRequestBody(
    messages: ChatMessage[],
    model: string,
    stream: boolean = true,
    options?: GenerationOptions
): object {
    // æå– system message
    const systemMessage = messages.find(m => m.role === 'system');
    const chatMessages = messages.filter(m => m.role !== 'system');

    const formattedMessages = chatMessages.map(m => {
        if (m.role === 'user' && m.images && m.images.length > 0) {
            return {
                role: m.role,
                content: [
                    ...m.images.map(img => {
                        // ç§»é™¤ data:image/xxx;base64, å‰ç¼€ï¼Œå› ä¸º Anthropic åªéœ€è¦ data éƒ¨åˆ†
                        const base64Data = img.replace(/^data:image\/\w+;base64,/, '');
                        // å°è¯•ä» base64 å‰ç¼€è·å– mime typeï¼Œé»˜è®¤ä¸º jpeg
                        let mediaType = 'image/jpeg';
                        const match = img.match(/^data:(image\/\w+);base64,/);
                        if (match) mediaType = match[1];

                        return {
                            type: 'image',
                            source: {
                                type: 'base64',
                                media_type: mediaType,
                                data: base64Data
                            }
                        };
                    }),
                    { type: 'text', text: m.content }
                ]
            };
        }
        return {
            role: m.role,
            content: m.content
        };
    });

    return {
        model,
        system: systemMessage?.content || '',
        messages: formattedMessages,
        stream,
        max_tokens: 4096,
        temperature: options?.temperature ?? 0.7,
        top_p: options?.top_p ?? 1.0,
    };
}

/**
 * å‘é€æ—¥å¿—åˆ°åç«¯ç»ˆç«¯
 */
async function logToBackend(tag: string, message: string, data?: any) {
    try {
        await fetch('http://localhost:8000/api/log', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ tag, message, data })
        });
    } catch {
        // å¿½ç•¥æ—¥å¿—å‘é€é”™è¯¯
    }
}

/**
 * æ—¥å¿—è®°å½•å·¥å…·
 */
function logRequest(url: string, model: string, body: any) {
    console.group('ğŸš€ [AI Service] Sending Request');
    console.log('Target URL:', url);
    console.log('Model:', model);
    console.log('Body:', body);
    console.groupEnd();

    // å‘é€åˆ°åç«¯ç»ˆç«¯
    logToBackend('AI Service', `Proxy Request -> ${url}`, { model, body });
}

function logError(url: string, error: any) {
    console.group('âŒ [AI Service] Request Failed');
    console.log('Target URL:', url);
    console.error('Error:', error);
    console.groupEnd();

    // å‘é€åˆ°åç«¯ç»ˆç«¯
    logToBackend('AI Service', `Proxy Request Failed -> ${url}`, { error: String(error) });
}

/**
 * é€šè¿‡åç«¯ä»£ç†å‘é€è¯·æ±‚
 */
async function sendProxyRequest(
    targetUrl: string,
    apiKey: string,
    payload: any,
    stream: boolean,
    signal?: AbortSignal
): Promise<Response> {
    const proxyUrl = 'http://localhost:8000/api/proxy/chat/completions';

    return fetch(proxyUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            target_url: targetUrl,
            api_key: apiKey,
            payload: payload
        }),
        signal
    });
}

/**
 * å‘é€èŠå¤©è¯·æ±‚ï¼ˆæµå¼ï¼‰
 */

export interface StreamCallbacks {
    onStart?: () => void;
    onToken?: (token: string) => void;
    onComplete?: (fullText: string) => void;
    onError?: (error: Error) => void;
}

/**
 * æ£€æŸ¥ API æ˜¯å¦å·²é…ç½®
 */
export function checkApiConfigured(): boolean {
    const api = getActiveLlmApi();
    return api !== null && !!api.apiKey && !!api.baseUrl;
}

/**
 * è·å–å½“å‰ API é…ç½®ä¿¡æ¯
 */
export function getCurrentApiInfo(): { name: string; model: string } | null {
    const api = getActiveLlmApi();
    if (!api) return null;
    return { name: api.name, model: api.model };
}

/**
 * å‘é€èŠå¤©è¯·æ±‚ï¼ˆæµå¼ï¼‰
 */
export async function streamChat(
    userMessages: ChatMessage[],
    callbacks: StreamCallbacks,
    abortController?: AbortController,
    options?: GenerationOptions
): Promise<string> {
    const api = getActiveLlmApi();
    if (!api) {
        throw new Error('æœªé…ç½® APIï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ  API é…ç½®');
    }

    // æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºè¯ï¼‰
    const systemPrompt = buildSystemPrompt();
    const messages: ChatMessage[] = [
        { role: 'system', content: systemPrompt },
        ...userMessages,
    ];

    // æ ¹æ® API æ ¼å¼æ„å»ºè¯·æ±‚
    const isAnthropic = api.format === 'anthropic';
    const body = isAnthropic
        ? buildAnthropicRequestBody(messages, api.model, true, options)
        : buildOpenAIRequestBody(messages, api.model, true, options);

    // æ„å»ºç›®æ ‡ URL
    let targetUrl = api.baseUrl;
    if (!targetUrl.endsWith('/')) targetUrl += '/';
    if (isAnthropic) {
        targetUrl += 'messages';
    } else {
        targetUrl += 'chat/completions';
    }

    // è®°å½•æ—¥å¿—
    logRequest(targetUrl, api.model, body);

    callbacks.onStart?.();

    try {
        // ä½¿ç”¨åç«¯ä»£ç†
        const response = await sendProxyRequest(
            targetUrl,
            api.apiKey,
            body,
            true,
            abortController?.signal
        );

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Proxy Error: ${response.status} - ${errorText}`);
        }

        if (!response.body) {
            throw new Error('å“åº”æ²¡æœ‰æ•°æ®æµ');
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let buffer = '';
        let fullText = '';

        while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || '';

            for (const line of lines) {
                const trimmed = line.trim();
                if (!trimmed || trimmed === 'data: [DONE]') continue;
                if (!trimmed.startsWith('data: ')) continue;

                // è§£æ SSE æ•°æ®
                // ä»£ç†å¯èƒ½ä¼šè½¬å‘åŸå§‹æ•°æ®ï¼Œæˆ–è€…æˆ‘ä»¬å¯èƒ½éœ€è¦æ ¹æ®ä¸åŒæ¨¡å‹è§£æ
                // ç›®å‰å‡è®¾ä»£ç†è½¬å‘äº†æ ‡å‡† SSE

                try {
                    const jsonStr = trimmed.slice(6);
                    const json = JSON.parse(jsonStr);

                    let content = '';
                    if (isAnthropic) {
                        if (json.type === 'content_block_delta') {
                            content = json.delta?.text || '';
                        }
                    } else {
                        // OpenAI æ ¼å¼
                        content = json.choices?.[0]?.delta?.content || '';
                    }

                    if (content) {
                        fullText += content;
                        callbacks.onToken?.(content);
                    }
                } catch {
                    // å¿½ç•¥è§£æé”™è¯¯
                }
            }
        }

        callbacks.onComplete?.(fullText);
        return fullText;

    } catch (error) {
        if (error instanceof Error && error.name === 'AbortError') {
            console.log('ğŸ›‘ [AI Service] Request Aborted');
            return '';
        }
        logError(targetUrl, error);
        callbacks.onError?.(error instanceof Error ? error : new Error(String(error)));
        throw error;
    }
}

/**
 * å‘é€èŠå¤©è¯·æ±‚ï¼ˆéæµå¼ï¼‰
 */
export async function chat(userMessages: ChatMessage[]): Promise<string> {
    const api = getActiveLlmApi();
    if (!api) {
        throw new Error('æœªé…ç½® APIï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­æ·»åŠ  API é…ç½®');
    }

    const systemPrompt = buildSystemPrompt();
    const messages: ChatMessage[] = [
        { role: 'system', content: systemPrompt },
        ...userMessages,
    ];

    const isAnthropic = api.format === 'anthropic';
    const body = isAnthropic
        ? buildAnthropicRequestBody(messages, api.model, false)
        : buildOpenAIRequestBody(messages, api.model, false);

    let targetUrl = api.baseUrl;
    if (!targetUrl.endsWith('/')) targetUrl += '/';
    targetUrl += isAnthropic ? 'messages' : 'chat/completions';

    logRequest(targetUrl, api.model, body);

    try {
        const response = await sendProxyRequest(targetUrl, api.apiKey, body, false);

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} - ${errorText}`);
        }

        // æ³¨æ„ï¼šä»£ç†å¯èƒ½è¿”å›æµå¼æ•°æ®ï¼Œè¿™é‡Œæˆ‘ä»¬éœ€è¦ä»æµä¸­è¯»å–å®Œæ•´å“åº”
        // ä½†å¦‚æœæœªè¯·æ±‚ stream=trueï¼ŒOpenAI é€šå¸¸è¿”å›å®Œæ•´ JSON
        // ä¸ºä¿é™©èµ·è§ï¼Œæˆ‘ä»¬è¯»å–æ•´ä¸ªå“åº”ä½“
        // TODO: ä»£ç†ç›®å‰æ€»æ˜¯è¿”å› StreamingResponseï¼Œè¿™å¯èƒ½éœ€è¦ä¼˜åŒ–å¯¹éæµå¼çš„æ”¯æŒ
        // æš‚æ—¶å‡è®¾ç”¨æˆ·æ€»æ˜¯ä½¿ç”¨æµå¼ç»„ä»¶è°ƒç”¨ï¼ˆchat å‡½æ•°å®é™…ä¸Šæœªåœ¨ UI ä¸­ä½¿ç”¨ï¼‰

        // ä¸´æ—¶å¤„ç†ï¼šä»æµä¸­æ‹¼è£…
        const reader = response.body?.getReader();
        if (!reader) throw new Error('No body');

        const decoder = new TextDecoder();
        let fullResponse = '';
        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            fullResponse += decoder.decode(value);
        }

        // å°è¯•è§£æå®Œæ•´ JSONï¼ˆå¯¹äºéæµå¼å“åº”ï¼‰
        // ä½†ç”±äºä»£ç†æ˜¯æµå¼çš„ï¼Œè¿™å¯èƒ½å¾ˆå¤æ‚ã€‚å»ºè®® UI å…¨éƒ¨è½¬å‘æµå¼ã€‚

        return "Non-streaming chat via proxy is not fully optimized yet. Please use streaming.";

    } catch (error) {
        logError(targetUrl, error);
        throw error;
    }
}

/**
 * æµ‹è¯• API è¿æ¥
 */
export async function testApiConnection(api: ApiConfig): Promise<boolean> {
    const isAnthropic = api.format === 'anthropic';

    const testMessages: ChatMessage[] = [
        { role: 'user', content: 'Hi' }
    ];

    const body = isAnthropic
        ? buildAnthropicRequestBody(testMessages, api.model, false)
        : buildOpenAIRequestBody(testMessages, api.model, false);

    let targetUrl = api.baseUrl;
    if (!targetUrl.endsWith('/')) targetUrl += '/';
    targetUrl += isAnthropic ? 'messages' : 'chat/completions';

    console.log(`ğŸ“¡ [AI Service] Testing Connection via Proxy: ${targetUrl}`);

    try {
        const response = await sendProxyRequest(targetUrl, api.apiKey, body, false);
        console.log(`âœ… [AI Service] Connection Test: ${response.ok ? 'Success' : 'Failed'}`);
        return response.ok;
    } catch (e) {
        console.error('âŒ [AI Service] Connection Test Error:', e);
        return false;
    }
}
